---
title: "3340 Final"
author: "Eric Reich, Zheng Ge"
date: "25/11/2020"
output: pdf_document
---

```{r}
#Add new data point and check the factors in the catagorical variables


library(faraway)
library(MASS)

car.data=read.csv("https://raw.githubusercontent.com/eric-reich-dal/3340-Final-Data/main/car%20data.csv")


Newdata=c("New Data Car", 2003, 30,60,300000,"Petrol", "Individual", "Manual", "3") 
#added new data point Price = 30, present price =60, year = 2003, KM driven = 300000, fuel type = Petrol, Seller type = Individual, Transmission = Manual,  Owner = 3rd. 

#I chose this because there is already expensive outliers from new, high end cars, so I made an expensive old car with bad km driven to mess with the leaverage.My thought process in the car is an old beater but looks like a car from a famous movie or was a well known car for the way in looked and has changed hands/been used a lot, but is still worth a lot of money.  


car.data=rbind(car.data, Newdata)

#Find how many dummy variable are needed

levels(as.factor(car.data$Fuel))
levels(as.factor(car.data$Seller_Type))
levels(as.factor(car.data$Transmission))
levels(as.factor(car.data$Owner))


```

```{r}
#create dummy variables and make a prediction


y=as.numeric(car.data$Selling_Price)

x.year=as.numeric(car.data$Year)

x.pres=as.numeric(car.data$Present_Price)

x.km=as.numeric(car.data$Kms_Driven)


x.fuel.p=ifelse(car.data$Fuel_Type=="Petrol",1,0)
x.fuel.d=ifelse(car.data$Fuel_Type=="Diesel",1,0)
#Petrol = 1,0; Diesel = 0,1; CNG = 0,0


x.sell.i=ifelse(car.data$Seller_Type=="Individual",1,0) 
#Individual = 1; Dealer = 0

x.tran=ifelse(car.data$Transmission=="Manual",1,0)  
#Manual = 1; Automatic = 0

x.N.own=ifelse(car.data$Owner=="0",1,0)  
x.1.own=ifelse(car.data$Owner=="1",1,0)  
#New = 1,0; pre owned once = 0,1; pre owned 3 times = 0,0

car=data.frame(y,x.year, x.pres, x.km,x.fuel.p,x.fuel.d,x.sell.i,x.tran,x.N.own,x.1.own)

X=cbind(rep(1,302),x.year,x.pres, x.km,x.fuel.p,x.fuel.d,x.sell.i,x.tran,x.N.own,x.1.own)

#I would expect newness to be a large factor in the model based on my knowledge of the cost of new cars being greater than older cars. KM, year and owner seem likely to be connected due to their connections with newness. I would also imagine that dealers would sell for higher prices, though I do not know enough to say that confidantly. People tend to buy automatic, but there are many people that prefer manual. Type of fuel used is something i have very little knowledge about. And presentation price is also something i know little about.  




```



```{r}
#fit the model and examine coefficients 

lm.car=lm(y~., data=car)
summary(lm.car)

#low p vaue for the model shows there is an affect given every variable is included. x.fuel.p and x.fuel.d p values are above 0.05 (these are dummy variables so must be evaluated different) together implying fuel type is not significant. X.N.own and x.1.own have p values above 0.05 (dummy variables again) implying number of owners is not significant. x.km also has high p, so it may also be insignificant. based on this model price (pr) increases as year increases (older is cheaper as predicted). pr decreases with presentation price (presented for more = selle for more). Both owner and fuel look odd to me, though owner more than fuel.  
```




```{r}
 library(plyr)


#check for multicollinearity

# changing indicator variable with more than 1 factor to numeric so they can be used to compare plots 

x.fuel=revalue(car.data$Fuel_Type, c("CNG"=0, "Diesel"=1, "Petrol"=2))#CNG=0, Deisel=1, Petrol=2 
x.fuel=as.numeric(x.fuel)
x.own=revalue(car.data$Owner, c("0"=0, "1"=1, "3"=2)) #New car = 0, 1st owner = 1, 3 = 2
x.own=as.numeric(x.own)
car.data.num=data.frame(y,x.year, x.pres, x.km,x.fuel,x.sell.i,x.tran,x.own) 

pairs(car.data.num)
vif(car[,-1])
vif(car.data.num[,-1])

# selling price apears to correlate with year, there is a strong correlation between selling price and present price, there is some correlation between km and price though it is difficult to say. Deisel seems to have greater affect on price than CNG and petrol. Dealer also tend to have higher price. Manual seems to have higher price but plot is unclear. New cars tend to sell for more, as expected. 
#year and x.pres appear to have vague correlation. As does year and km, though negative (makes sense as older cars are more likely to be driven more), Fuel appears to be more diesel in newer cars.transmision and seller look vague. number of owners decrease with newer cars
#increase with km, maybe some correlation. Present price seems slightly higher for diesel. seller looks vague. transmission looks vague. new cars present for more, though older cars present higher than somewhat old cars (non linear?). KM increases with fuel type, petrol is the highest (most readily available and cheapest in many places in the world). individual sellers had higher km usage. transmission looks vague. number of owners looks vague (unusual because why would previously unowned cars have lots of km?)
#Plots between the last 4 variables are vague and don't give any info because they are all indicator variables

#Correlation between year and present price are as expected. I expected more noticable correlation between km and price. higher prices for 0 owner makes sense, and the lower priced vehicles with 0 owners may be test vehicles which makes sense for the lower prices. Dealers generally selling for more makes sense because less haggling and more set price than individuals. I would expect year and number of owners to correlate more, especially vehicles with 0 owners. Correlation between year and km driven also makes sense. 0 owners and high km makes sense due to test cars. 

#Based on the plots there doesn't seem to be strong evidence of multicolinearity. Though logoically I think there are interactions between km driven, year and number of owners. 


#VIF for model with dummy variables fuel and owner variables appear to be multicolinear, but when dummy variable are combined, multicolinearity dissapears. 


```


```{r}
#investigate the residuals, Influential and leaverage 

plot(lm.car)

#Plot 1, we see a fanning, implying that variability is increasing and transforming the graph may be a good idea by Using the square root to stabalize the variance
#Plot 2, QQ plots are wonky and there are 3 significant outliers 
#Plot 3, 3 outliers


H=X%*%solve(t(X)%*%X)%*%t(X)
hii=diag(H)
p=6
n=302
lev=which(hii>2*p/n)



which(cooks.distance(lm.car)>1)

#there are 45 leaverage points based on the H matrix and three influential points at 86, 87 and 302 based on cooks distance which is makes sense when looking at the residuals

#it seems as though the data has non constant variance and needs to be stabalized via a transformation and it has high influence. The leaverage also seems weird.

```


```{r}



plot(x.pres, y, xlab="Presentation Price", ylab="Selling Price")




```




```{r}
#transforming the data

sq.y=sqrt(y)
tran.car.1=data.frame(sq.y,x.year, x.pres, x.km,x.fuel.p,x.fuel.d,x.sell.i,x.tran,x.N.own,x.1.own)


lm.car.tran.1=lm(sq.y~.,data=tran.car.1)
summary(lm.car.tran.1)
plot(lm.car.tran.1)


#plot 1, looks better, but there is still a small fanning effect
#plot 2, tail action still looks weird
```


```{r}
ln.y=log(y)
tran.car.2=data.frame(ln.y,x.year, x.pres, x.km,x.fuel.p,x.fuel.d,x.sell.i,x.tran,x.N.own,x.1.own)

lm.car.tran.2=lm(ln.y~.,data=tran.car.2)
summary(lm.car.tran.2)
plot(lm.car.tran.2)
#plot 1, looks way better. No noticable fanning 
#plot 2, plot looks way betterm but still weird tail action 

which(cooks.distance(lm.car.tran.2)>1)

#Decided to go with the ln transfromation, as the variance looked more random and 302 influence of 302 was minimized in cooke distance and residual plot

#there still appears to be an outlier at 87, based on the plots and cooke 

full.tran.car=data.frame(ln.y,x.year, x.pres, x.km,x.fuel,x.sell.i,x.tran,x.own)



```

```{r}
#Visualize the effect of the influence point

car.d.87=full.tran.car[-87,]
null.model= lm(ln.y~1)
car.87=data.frame(ln.y,x.year, x.pres, x.km,x.fuel,x.sell.i,x.tran,x.own)[-87,]

car.model.d.87=lm(ln.y~., data=car.d.87)
summary(car.model.d.87)

car.model.87=lm(ln.y~., data=car.87)
step=step(null.model, scope = list(lower=null.model, upper=car.model.87), direction = "both")


l.d=leaps(x=car.d[,-1], y=car.d[,1],method="adjr2")
l
 

```




```{r}
#determine which varibales are actually needed

full.model=lm(ln.y~., data=full.tran.car)
step=step(null.model, scope = list(lower=null.model, upper=full.model), direction = "both")

step=step(null.model, scope = list(lower=null.model, upper=lm.car.tran.2), direction = "both")

# usin the stepwise comparison, we determine that the "best" model is ln.y = x.sell.i + x.pres + x.year + x.fuel + x.own
#Km and transmission have been removed from the model
```

```{r}
library(leaps)

l=leaps(x=car.d[,-1], y=car.d[,1],method="adjr2")
l
 
c(55,l$which[55,])
c(51,l$which[51,])
c(50,l$which[50,])
c(49,l$which[49,])
c(48,l$which[48,])
c(43,l$which[43,])
c(42,l$which[42,])
c(41,l$which[41,])
c(40,l$which[40,])
c(38,l$which[38,])
c(31,l$which[31,])
c(30,l$which[30,])
c(29,l$which[29,])
c(28,l$which[28,])
c(18,l$which[18,])

#based on the adjusted R2, there seems to be 15 possible models as listed below. 

#55 @ 0.889624255 = All 
#51 @ 0.888295188 = -fuel
#50 @ 0.889273061 = -own 
#49 @ 0.889866619 = -tran
#48 @ 0.889959711 = -km
#43 @ 0.888118824 = -fuel -own
#42 @ 0.888478215 = -fuel -tran
#41 @ 0.888541218 = -fuel -km
#40 @ 0.889469980 = -tran -own
#38 @ 0.890212779 = -km -tran
#31 @ 0.888257488 = -fuel -own -tran 
#30 @ 0.888317091 = -km -fuel -own
#29 @ 0.888749946 = -km -fuel -tran
#28 @ 0.889787240 = -km -own -tran
#18 @ 0.888488099 = -km -fuel -own -tran


# the highest adj R2 reveal the same model as in the stepwise comparison as price = year + presenting price + fuel type + seller + number of owners
# the r squared are very simillar to one another, as such one best model does not seem likely.
# year, presening price and seller show up in every model
#Km was removed the fewest times at 6 and fuel the most at 8. 


```
```{r}
step.model=lm(ln.y~x.sell.i + x.pres + x.year + x.fuel.d +  x.1.own + x.N.own)

summary(step.model)


plot(step.model)
```




